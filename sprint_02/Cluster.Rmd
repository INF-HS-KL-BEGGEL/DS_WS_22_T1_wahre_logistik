---
title: "Clustering"
output: html_notebook
---

```{r message=FALSE, warning=FALSE}
library(DBI)
library(dplyr)
library(odbc)
library(lubridate)
library(tidyverse)
library(leaflet)
library(factoextra)


library(tidyverse)
library(readxl)
library(FactoMineR)
readRenviron("../env_files/.Renviron.postgres")
```

```{r}
con <- dbConnect(drv=RPostgres::Postgres(),
                 dbname=Sys.getenv("dbname"),
                 host=Sys.getenv("host"),
                 port=Sys.getenv("port"),
                 password=Sys.getenv("password"),
                 user=Sys.getenv("user"))
```

```{r}
con <- DBI::dbConnect(odbc::odbc(),
                      Driver   = Sys.getenv("driver"),#"PostgreSQL Unicode",
                      Server   = Sys.getenv("host"),
                      Database = Sys.getenv("dbname"),
                      UID      = Sys.getenv("user"),
                      PWD      = Sys.getenv("password"),
                      Port     = Sys.getenv("port"))
```

# Clustering
Es wird ein Clustering unterschiedlicher Daten mit dem K-Means Algorithums vorgenommen.

```{r include=FALSE}
#customers with retail value and amount of orders
käufeProKunde <- dbGetQuery(conn=con, statement = "Select kunde, lieferschein, sum(vk_preis_num) as verkaufswert From verkaeufe Where DATE_PART('week',datum) !=1 OR DATE_PART('week',datum) !=53 Group By kunde,lieferschein")
käufeProKunde <- käufeProKunde %>% ungroup()
käufeProKunde <- käufeProKunde %>% group_by(kunde) %>% summarize(bestellungen=n(), verkaufswert=sum(verkaufswert)) %>% arrange(desc(verkaufswert))


#scaled table
käufeProKunde <- käufeProKunde %>% mutate(kunde_sc=scale(kunde), bestellungen_sc=scale(bestellungen), verkaufswert_sc=scale(verkaufswert))
käufeProKunde_scaled <- käufeProKunde %>% select(kunde_sc, bestellungen_sc, verkaufswert_sc)


käufeProKunde_scaled
käufeProKunde
```

## Kundengruppen nach Bestellhäufigkeit und Verkaufswert

Beim Clustering mit K-means stellt sich zunächst die Frage, wie viele Cluster gebildet werden sollen. Die Menge der Cluster wird nicht vom Clustering Algorithmus slebst berechnet und stellt stattdessen einen Parameter für diesen dar. Um besser entscheiden zu können, wie viele Cluster sinnvoll wären, wird eine Methode zur Cluster Validierung genutzt - Ellbow Method.
Die resultierende Kurve sinkt asymptopisch ab. Hirbei wird der Punkt als optimale Cluster Anzahl betrachtet, bei dem die Kurve beginnt sich abzuflachen.
Daraus schließen wir die eine Clustermenge von 4.

```{r echo=FALSE}
# Fancy K-Means
#we cut a few out of the table for this analysis [1:5000, ], else the function wont operate cause to a to big memory usage
fviz_nbclust(käufeProKunde_scaled %>% select(bestellungen_sc,verkaufswert_sc), kmeans, nstart=100, method = "wss")
```

Das Ergebnis des Clustering sieht aus wie folgt:

```{r echo=FALSE}
# Fancy K-Means
kmeans_fancy <- kmeans(käufeProKunde_scaled %>% select(bestellungen_sc,verkaufswert_sc), 4, nstart = 100)
kmeans_fancy
# plot the clusters
fviz_cluster(kmeans_fancy, data = käufeProKunde_scaled %>% select(gewichtung_bestellungen=bestellungen_sc,gewichtung_verkaufswert=verkaufswert_sc), geom = c("point"),ellipse.type = "convex")
```


```{r include=FALSE}
#add the results to the primary table
final_data <- cbind(käufeProKunde, cluster = kmeans_fancy$cluster)
final_data
```


```{r include=FALSE}
#get the summarised values for each cluster
sumOfClusters <- final_data %>% select(cluster,verkaufswert,bestellungen)
meanVerkaufswert <- mean(sumOfClusters$verkaufswert)
meanBestellungen <- mean(sumOfClusters$bestellungen)
amountVerkaufswert <- length(sumOfClusters$verkaufswert)
amountBestellungen <- length(sumOfClusters$bestellungen)
sumVerkaufswert <- sum(sumOfClusters$verkaufswert)
sumBestellungen <- sum(sumOfClusters$bestellungen)
  
sumOfClusters <- sumOfClusters %>% group_by(cluster) %>% summarize(
  verkaufswertDesClusters=sum(verkaufswert),
  verkaufswert_rel=verkaufswertDesClusters/(sumVerkaufswert/100),
  verkaufswert_avg_imCluster=mean(verkaufswert),
  bestellungenDesClusters=sum(bestellungen),
  bestellungen_rel=bestellungenDesClusters/(sumBestellungen/100),
  bestellungen_avg_imCluster=mean(bestellungen),
  kunden=n())
sumOfClusters
```

Wir ordnen die Cluster nach ihrer Größe und es wird auffällig, dass einer die Cluster mit weitem Abstand die Dominanteste ist und damit die meisten Kunden zu ihm gehören.

```{r echo=FALSE}
#Bar diagramm for total and rel. retail value per cluster
ggplot(sumOfClusters %>% select(cluster,kunden), aes(x=cluster, y=kunden)) +
  geom_bar(stat="identity", fill="steelblue")+
  geom_text(aes(label=kunden), vjust=-0.3, size=3.5)+
  theme_minimal()
```

Betrachten wir aber dazu noch den tatsächlichen Umsatz der jeweiligen Gruppen fällt auf, dass die beiden kleinsten Gruppen mit nur 14 bzw. 0.26 % der järhlichen Kunden zusammen für 25% des Umsatzes verantwortlich sind.

```{r echo=FALSE}
#Bar diagramm for total and rel. retail value per cluster
ggplot(sumOfClusters %>% select(cluster,verkaufswertDesClusters,verkaufswert_rel), aes(x=cluster, y=verkaufswertDesClusters)) +
  geom_bar(stat="identity", fill="steelblue")+
  geom_text(aes(label=paste(as.character(round(verkaufswert_rel, digits = 2)),"%")), vjust=+3, size=3.5)+
  geom_text(aes(label=verkaufswertDesClusters), vjust=+1.3, size=3.5)+
  theme_minimal()
```











```{r}
#customer wth every material
materialProKunde <- dbGetQuery(conn=con, statement = "Select kunde, materialnummer From verkaeufe Order By kunde")
onlyFans <- materialProKunde %>% select(kunde) %>% distinct()
onlyMaterials <-  materialProKunde %>% select(materialnummer) %>% distinct()
countOfFans <- nrow(onlyFans)
materialProKunde
onlyFans
countOfFans
onlyMaterials
```

```{r}
#make materialnumer an numeric id; necessary for the kmeans alg.
materialToID <- onlyMaterials %>% mutate(id=row_number())
materialToID
#add to 'materialProKunde'
materialProKunde <- inner_join(x=materialProKunde, y=materialToID, by="materialnummer")
materialProKunde
#remove material number as its no numeric value, which is necassary for kmeans
mIDproKunde <- materialProKunde %>% select(kunde, id)
mIDproKunde
```

```{r}
#cross function for article 1 bought with article 2
#it actually does it by group kunde, because to make it at once is not supported by the API, cause to the to high memory consumption
# to the end they wil merged back together
#WARNING!: This will need some time
crossGroups = function(DataFrameList)
{
    DataFrameList <- crossing(DataFrameList,DataFrameList, .name_repair = "unique")
    DataFrameList <- DataFrameList[DataFrameList$id...2 != DataFrameList$id...4, ] 
    DataFrameList <- DataFrameList %>% select(material_eins=id...2,material_zwei=id...4)
    return(DataFrameList)
}

materialGekauftMitProGruppe <- mIDproKunde %>% group_by(kunde) %>% group_split()
materialGekauftMitProGruppe <- lapply(materialGekauftMitProGruppe %>% head(), crossGroups)

materialGekauftMit <- materialGekauftMitProGruppe[[1]]
materialGekauftMit <- subset(materialGekauftMit,FALSE)

for (singleGroup in materialGekauftMitProGruppe)
{
  materialGekauftMit <- full_join(x=materialGekauftMit, y=singleGroup) %>% distinct()
}

materialGekauftMit
```


```{r echo=FALSE}
# Fancy K-Means
#we cut a few out of the table for this analysis [1:10000, ], else the function wont operate cause to a to big memory usage
fviz_nbclust(scale(materialGekauftMit)[1:10000, ], kmeans, nstart=100, method = "wss")
```

```{r echo=FALSE}
# Fancy K-Means
gc()
kmeans_fancy <- kmeans(scale(materialGekauftMit), 3, nstart = 100, algorithm="Lloyd")
kmeans_fancy
# plot the clusters
fviz_cluster(kmeans_fancy, data = scale(materialGekauftMit), geom = c("point"),ellipse.type = "convex")
```

```{r include=FALSE}
#add the results to the primary table
final_material <- cbind(materialGekauftMit, cluster = kmeans_fancy$cluster)
final_material
```




# Datenbankverbindung beenden
```{r}
dbDisconnect(con)
```